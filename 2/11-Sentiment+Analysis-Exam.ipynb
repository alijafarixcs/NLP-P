{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals\n",
    "import re, codecs\n",
    "from collections import Counter\n",
    "from nltk.tokenize.api import TokenizerI\n",
    "import sys\n",
    "from os import path\n",
    "import codecs\n",
    "import itertools\n",
    "import fasttext\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import csv\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from hazm import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dictionary-Based Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Posdic = ['مناسب','عالی','بهتر','برتر','شیک','زیبا','کارآزموده','گشاده','چابکی','ایستادگی','تازگی','آسوده','ستوده','شیفته','فراورده','استواری','شکوفیدن','کوشیدن','آمرزیده','برگزیده','گشوده','آراستن','آرِستن','بخشیده','غنوده','دلپذیر','ستودن','شایستن','نازیدن','بزرگ','دلیری','زیرکی','زبردستی','خشنودی','ورزیده','وارستگی','بسامانی','پیشرفته','مفید','تازه','ارزش','زیبندگی','آراسته','برازندگی','سريع','تندی','راستی','تميز','پاکیزگی','روشن','سبک','ارزان','ارزون','دلبسته','دلداده','دلشده','پاسداری','پرهیزکاری','خوشدلی','خوشی','رهایی','آسودن','رخشیدن','روان','قوی','آسون','پختگی','پایمردی','پایندانی','پایندگی','شيفته','زبانزد','پایداری','توانستن','بردباری','خجستگی','رستگاری','درخشندگی','خوبی','دانا','مهربان','روشنگر','\\xa0خوب','بهبودی','پاکبازی','درخشیدن','خندان','پهلوانی','پیروزی','دلخوشی','بالیدن','بهروزی','خوشمزه']\n",
    "\n",
    "Negdic = ['زشتی','بد','سرد','کثيف','آلوده','ربایندگی','پخمگی','خودکامگی','غلط','گران','گرون','چغلی','خرحمالی','دستمالی','دلخوری','تیغیدن','ریدن','درماندگی','رسوایی','دستگیری','تاخته','پلیدی','لاغر','يواشكی','خسته','تنگدستی','باختن','بازاندن','جنگیدن','شَخلیدن','غارتیدن','کِشتن','ضعيف','دردمندی','دریدگی','زنندگی','چاپیدن','ژولیده','آشفتن','\\xa0سخت','خودشیرینی','دزدیدن','زاری','سوخته','سرافکنده','پایمال','پرافکنده','هراسیده','کوچک','کوتاه','كوچك','تنبل','آبكی','کوچيک','گذشته','واخوردگی','دریوزگی','دریدن','رهزنی','آزرده','فریفتن','سفت','پولكی','آسیب','تنگی','پوکیدن','پوکاندن','تاختن','تبیدن','ژولیدن','فرساییدن','مُردن','خودسری','نالیدن','آزدن','آزردن','سياه','آشفته','وامانده','افکنده','باخته','برشته','پایسته','تارانده','تفته','کشته','کشیده','خودکشی','سرشکسته','زدگی','تاریک','تلخ','ورشکسته','برانگیخته','پلاسیده','تنبیده','دریده','شکافته','غراشیده','گزیده','نازپرورده','تاریکا','تاریکی','وارسیدن','فروختن','درازدستی','وارفته','فرسودن','واخورده','پرحرف','ترکیده','وارفتگی','خارجی','وابسته','گریاندن','شکستن','گندیدن','وادادن','واریخته','درمانده','لهیده','نخراشیده','ورماندگی','بدهکاری','پژمردگی','چلچلی','گُسیختن','واسوختن','پژمرده','فریفته','نابسوده','وازده','تازانده','نارس','نارسیده','بازپرسی','بازجویی','بازرسی']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean(text):\n",
    "    normalizer = Normalizer()\n",
    "    # Remove URLs, User Mentions and Hashtags and Retweet and Number\n",
    "    text = normalizer.normalize(re.sub(r\"(?:\\@|https?\\://|\\d+)\\S+\", \"\", text)\n",
    "                                .replace(\"RT\", \"\").replace(\"#\", \"\").replace(\"_\", \" \"))\n",
    "\n",
    "    # Replace Repetitions of Punctuation and Charector\n",
    "    text = ''.join(ch for ch, _ in itertools.groupby(text))\n",
    "\n",
    "    # Remove Punctuation\n",
    "    #text = re.sub(r'[^\\w\\s]', '', text)\n",
    "\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stwd = ['همچنان', 'مدت', 'چیز', 'سایر', 'جا', 'طی', 'کل', 'کنونی', 'بیرون','های', 'مثلا', 'کامل','ها', 'کاملا','گیرد','شود','است', 'آنکه', \n",
    "            'موارد', 'واقعی', 'امور', 'اکنون', 'بطور', 'بخشی', 'تحت', 'چگونه', 'عدم', 'نوعی', 'حاضر', 'وضع', 'مقابل', 'کنار', 'خویش', 'نگاه', 'درون',\n",
    "            'زمانی', 'بنابراین', 'تو', 'خیلی', 'بزرگ', 'خودش', 'جز', 'اینجا', 'مختلف', 'توسط', 'نوع', 'همچنین', 'آنجا', 'قبل', 'جناح', 'اینها', 'طور', 'شاید',\n",
    "            'ایشان', 'جهت', 'طریق', 'مانند', 'پیدا', 'ممکن', 'کسانی', 'جای', 'کسی', 'غیر', 'بی', 'قابل', 'درباره', 'جدید', 'وقتی', 'اخیر', 'چرا', 'بیش',\n",
    "            'روی', 'طرف', 'جریان', 'زیر', 'آنچه', 'البته', 'فقط', 'چیزی', 'چون', 'برابر', 'هنوز', 'بخش', 'زمینه', 'بین', 'بدون', 'استفاد', 'همان', 'نشان',\n",
    "            'بسیاری', 'بعد', 'عمل', 'روز', 'اعلام', 'چند', 'آنان', 'بلکه', 'امروز', 'تمام', 'بیشتر', 'آیا', 'برخی', 'علیه', 'دیگری', 'ویژه', 'گذشته', 'انجام',\n",
    "            'حتی', 'داده', 'راه', 'سوی', 'ولی', 'زمان', 'حال', 'تنها', 'بسیار', 'یعنی', 'عنوان', 'همین', 'هبچ', 'پیش', 'وی', 'یکی', 'اینکه', 'وجود'\n",
    "            , 'شما', 'پس', 'چنین', 'میان', 'مورد', 'چه', 'اگر', 'همه', 'نه', 'دیگر', 'آنها', 'باید', 'هر', 'او', 'ما', 'من', 'تا', 'نیز', 'اما', \n",
    "            'یک', 'خود', 'بر', 'یا', 'هم','ای', 'را','دارد', 'این',\"می\", 'با','دارد','،',',','.', 'آن', 'برای', 'و', 'در', 'به', 'که', 'از']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from hazm import *\n",
    "\n",
    "def Lexicon(Text):\n",
    "    SentimentTotalDict = 0\n",
    "    SentencesLevels = []\n",
    "    Hassenses = []\n",
    "    SentimentTotalSent = 0\n",
    "    \n",
    "    sentences = sent_tokenize(clean(Text)) \n",
    "    for sent in sentences:\n",
    "        Hassense = 0\n",
    "        totalsente = 0\n",
    "        wordlist = word_tokenize(sent)\n",
    "        for w in wordlist:\n",
    "            if w in Posdic:\n",
    "                SentimentTotalDict += 1\n",
    "                totalsente += 1\n",
    "                Hassense = 1\n",
    "                print(w)\n",
    "            elif w in Negdic:\n",
    "                SentimentTotalDict -= 1\n",
    "                totalsente -= 1\n",
    "                Hassense = 1\n",
    "                print(w)\n",
    "        SentencesLevels.append(totalsente)\n",
    "        Hassenses.append(Hassense)\n",
    "                \n",
    "    for x in SentencesLevels:\n",
    "        if x > 0:\n",
    "            SentimentTotalSent +=1\n",
    "        elif x < 0:\n",
    "            SentimentTotalSent -=1\n",
    "    return(SentimentTotalDict,SentencesLevels,SentimentTotalSent,Hassenses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "زیبا\n",
      "مهربان\n",
      "ژولیده\n",
      "بد\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0, [1, 1, -2, 0, 0], 1, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Lexicon(\"زیبا بروفه آمد .علی پسر بسیار مهربان است :-). در مقابل رامین ژولیده و بد است! علی خوب نیست. فوتبال داریم.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "خوبی\n",
      "مهربان\n",
      "بد\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, [2, -1], 0, [1, 1])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Lexicon(\"علی پسر خوبی و مهربان است. رامین بد است\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "مهربان\n",
      "ژولیده\n",
      "بد\n",
      "خوبی\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0, [1, -2, 1, 0], 1, [1, 1, 1, 0])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Lexicon(\"😃😃😃 علی پسر بسیار مهربان است. در مقابل رامین ژولیده و بد و نامرد است! علی خوبی؟ فوتبال هنر است.\")\n",
    "\n",
    "#(SentimentTotalDict,[Sentences Level],SentimentTotalSent,Hassense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "خیلی خیلی معمولیه ، موقع خرید درباره اسم سنهایزر تعریفشو زیاد شنیدم ولی بعد خرید و استفاده متوجه شدم محصوله معمولی هستش، البته اینو بگم قبلش از هندزفری urBeats 2 استفاده میکردم که در قیاس با سنهایزر مثل مقایسه بوگاتی با پرایده! از لحاظ طراحی خوبه ولی کیفیت صدا معمولی بیس پایین! به هیچ وجه قابل قیاس با هدفون های Beats نیست!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
