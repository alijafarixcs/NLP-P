{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOL while scanning string literal (<ipython-input-2-ac043c3890ce>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-2-ac043c3890ce>\"\u001b[1;36m, line \u001b[1;32m3\u001b[0m\n\u001b[1;33m    text = 'امروز پردازش زبان طبیعي یکی از #جذاب ترین فیلدهای کاری است.\u001b[0m\n\u001b[1;37m                                                                       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m EOL while scanning string literal\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "text = 'امروز پردازش زبان طبیعي یکی از #جذاب ترین فیلدهای کاری است. این حوزه به فیلدهای  علم داده، یادگیری ماشین و آمار مرتبط می باشد'\n",
    "\n",
    "print(text) \n",
    "\n",
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "longtext = \"\"\"\n",
    "گلعذاری ز گلستان جهان ما را بس\n",
    "زین چمن سایه آن سرو روان ما را بس\n",
    "بنشین بر لب جوی و گذر عمر ببین\n",
    "کاین اشارت ز جهان گذران ما را بس\n",
    "یار با ماست چه حاجت که زیادت طلبیم\n",
    "دولت صحبت آن مونس جان ما را بس\n",
    "از در خویش خدا را به بهشتم مفرست\n",
    "\"\"\"\n",
    "\n",
    "longtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['امروز', 'پردازش', 'زبان', 'طبیعي', 'یکی', 'از', '#جذاب', 'ترین', 'فیلدهای', 'کاری', 'است.', 'این', 'حوزه', 'به', 'فیلدهای', '', 'علم', 'داده،', 'یادگیری', 'ماشین', 'و', 'آمار', 'مرتبط', 'می', 'باشد']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text2 = text.split(\" \")\n",
    "print(text2)\n",
    "len(text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['پردازش', 'فیلدهای', 'فیلدهای', 'یادگیری']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w for w in text2 if len(w) > 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "امروز\n",
      "پردازش\n",
      "طبیعي\n",
      "#جذاب\n",
      "داده،\n",
      "ماشین\n",
      "مرتبط\n"
     ]
    }
   ],
   "source": [
    "for w in text2:\n",
    "    if len(w) > 4 and len(w) < 7:\n",
    "        print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Endswith\n",
    "\n",
    "[w for w in text2 if w.endswith('،')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['#پایتون', '#کارها', '#تابع']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Startswith\n",
    "\n",
    "Tweet = \"اون اوایل که داشتم  #پایتون رو یاد می گرفتم واسه ابتدای ترین #کارها هم خودم کدشو می نوشتم. بعدها متوجه شدم واسه همشون یه #تابع آماده هست\"\n",
    "\n",
    "Tweet2 = Tweet.split(' ')\n",
    "\n",
    "[w for w in Tweet2 if w.startswith(\"#\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\ufeffمتن\\u200cکاوي، به داده\\u200cکاوي\\u200cاي که بر روی متن انجام شود اشاره دارد. همچنین به عنوان آنالیز متن نیز شناخته می\\u200cشود که منظور از آن فرایند استخراج اطلاعات با کیفیت از متن است. اطلاعات پر کیفیت، به\\u200cطور معمول از فهم الگوها و گرایش\\u200cها از طریق معانی و به وسیلهٔ یادگیری الگوهای آماری حاصل می\\u200cشود. متن کاوی معمولاً درگیر در فرایند ساختاردهی به ورودی\\u200cهای متنی (معمولاً تجزیه، همراه با افزودن برخی ویژگی\\u200cها تفاسیر زبانی و حذف موارد اضافی و درج موارد بعدی در پایگاه داده انجام می\\u200cگیرد)، استخراج الگوهای درون داده\\u200cهای ساختار یافته، و در نهایت ارزیابی و تفسیر خروجی\\u200cها است. «پر کیفیت» در متن کاوی معمولاً به ترکیبی از مرتبط بودن، نو ظهور بودن و جالب بودن اشاره دارد. وظایف متن کاوی معمول شامل دسته\\u200cبندی متون، خوشه بندی متون، استخراج معنی و مفهوم، تولید رده\\u200cبندی دانه\\u200cای، تجزیه و تحلیل احساسات، خلاصه کردن اسناد و مدلسازی ارتباط موجودیت\\u200cها است. (بطور مثال یادگیری ارتباط بین موجودیتها)',\n",
       " '',\n",
       " 'آنالیز متن درگیر در بازیابی اطلاعات، آنالیز لغوی برای مطالعه توزیع فرکانس لغات، شناخت الگو، برچسب گذاری/حاشیه نویسی، استخراج اطلاعات، تکنیک\\u200cهای داده کاوی شامل آنالیز اتصال و ارتباط، بصری سازی، و آنالیز پیشگویانه است. هدف نهایی، اساساً تبدیل متن به داده برای آنالیز از طریق کاربرد پردازش زبان\\u200cهای طبیعی و متدهای تحلیلی است.',\n",
       " '',\n",
       " 'یک کاربرد معمول، جهت اسکن مجموعه\\u200cای از اسناد نوشته شده در یک زبان طبیعی و مدل کردن مجموعه اسناد برای اهداف کلاس\\u200cبندی پیشگویانه یا پرکردن یک پایگاه داده یا ایندکس جستجو با اطلاعات استخراج شده\\u200cاست.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Open Txt File in Python\n",
    "\n",
    "file = open(r\"D:\\Text9\\data\\Text.txt\",mode='r',encoding='utf-8').read().splitlines()\n",
    "file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\ufeffمتن\\u200cکاوي، به داده\\u200cکاوي\\u200cاي که بر روی متن انجام شود اشاره دارد. همچنین به عنوان آنالیز متن نیز شناخته می\\u200cشود که منظور از آن فرایند استخراج اطلاعات با کیفیت از متن است. اطلاعات پر کیفیت، به\\u200cطور معمول از فهم الگوها و گرایش\\u200cها از طریق معانی و به وسیلهٔ یادگیری الگوهای آماری حاصل می\\u200cشود. متن کاوی معمولاً درگیر در فرایند ساختاردهی به ورودی\\u200cهای متنی (معمولاً تجزیه، همراه با افزودن برخی ویژگی\\u200cها تفاسیر زبانی و حذف موارد اضافی و درج موارد بعدی در پایگاه داده انجام می\\u200cگیرد)، استخراج الگوهای درون داده\\u200cهای ساختار یافته، و در نهایت ارزیابی و تفسیر خروجی\\u200cها است. «پر کیفیت» در متن کاوی معمولاً به ترکیبی از مرتبط بودن، نو ظهور بودن و جالب بودن اشاره دارد. وظایف متن کاوی معمول شامل دسته\\u200cبندی متون، خوشه بندی متون، استخراج معنی و مفهوم، تولید رده\\u200cبندی دانه\\u200cای، تجزیه و تحلیل احساسات، خلاصه کردن اسناد و مدلسازی ارتباط موجودیت\\u200cها است. (بطور مثال یادگیری ارتباط بین موجودیتها)',\n",
       " '',\n",
       " 'آنالیز متن درگیر در بازیابی اطلاعات، آنالیز لغوی برای مطالعه توزیع فرکانس لغات، شناخت الگو، برچسب گذاری/حاشیه نویسی، استخراج اطلاعات، تکنیک\\u200cهای داده کاوی شامل آنالیز اتصال و ارتباط، بصری سازی، و آنالیز پیشگویانه است. هدف نهایی، اساساً تبدیل متن به داده برای آنالیز از طریق کاربرد پردازش زبان\\u200cهای طبیعی و متدهای تحلیلی است.',\n",
       " '',\n",
       " 'یک کاربرد معمول، جهت اسکن مجموعه\\u200cای از اسناد نوشته شده در یک زبان طبیعی و مدل کردن مجموعه اسناد برای اهداف کلاس\\u200cبندی پیشگویانه یا پرکردن یک پایگاه داده یا ایندکس جستجو با اطلاعات استخراج شده\\u200cاست.']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = open(r\"D:\\Text9\\data\\Text.txt\",mode='r',encoding='utf-8').read().split(\"\\n\")\n",
    "file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   سلام به همه دوستان   \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'سلام به همه دوستان'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Strip\n",
    "\n",
    "TextStrip = \"   سلام به همه دوستان   \"\n",
    "print(TextStrip)\n",
    "TextStrip.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79\n",
      "6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Find\n",
    "\n",
    "TextFind = \"برای  #پیدا_کردن دوست باید یک چشمت  را ببندی و نگه داشتن #آن هر دو چشمت برای را\"\n",
    "print(len(TextFind))\n",
    "\n",
    "print(TextFind.find(\"#\"))\n",
    "\n",
    "TextFind.find(\"پایتون\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'تو برای وصل کردن آمدی__یا برای فصل کردن آمدی'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Join\n",
    "\n",
    "listt = (\"تو برای وصل کردن آمدی\",\"یا برای فصل کردن آمدی\")\n",
    "\n",
    "\" \".join( listt )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "تو برای وصل کردن آمدی یا برای فصل کردن آمدی\n"
     ]
    }
   ],
   "source": [
    "#Join\n",
    "\n",
    "a = \"تو برای وصل کردن آمدی\"\n",
    "b = \"یا برای فصل کردن آمدی\"\n",
    "c = a +  \" \" + b\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t1 = سلام\n",
      "True\n",
      "False\n",
      "False\n",
      "\n",
      "\n",
      "t2 = 123\n",
      "False\n",
      "True\n",
      "False\n",
      "\n",
      "\n",
      "t3 =   \n",
      "\n",
      "False\n",
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "#Type of string class\n",
    "\n",
    "t1 = \"سلام\"\n",
    "t2 = \"123\"\n",
    "t3 = \" \"\n",
    "\n",
    "print(\"t1 =\",t1)\n",
    "print(t1.isalpha())\n",
    "print(t1.isdigit())\n",
    "print(t1.isspace())\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"t2 =\",t2)\n",
    "print(t2.isalpha())\n",
    "print(t2.isdigit())\n",
    "print(t2.isspace())\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"t3 =\",t3,\"\\n\")\n",
    "print(t3.isalpha())\n",
    "print(t3.isdigit())\n",
    "print(t3.isspace())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"1 little pigs come out, or I'll huff, and I'll puff, and I'll blow your علی down.\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text10 = \"%d little pigs come out, or I'll %s, and I'll %s, and I'll blow your %s down.\" % (1, 'huff', 'puff', \"علی\")\n",
    "                                                                                           \n",
    "text10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 little pigs come out, or I'll huff, and I'll puff, and I'll blow your a down.\n",
      "1 little pigs come out, or I'll huff, and I'll puff, and I'll blow your aa down.\n",
      "2 little pigs come out, or I'll huff, and I'll puff, and I'll blow your aaa down.\n",
      "3 little pigs come out, or I'll huff, and I'll puff, and I'll blow your aaaa down.\n",
      "4 little pigs come out, or I'll huff, and I'll puff, and I'll blow your aaaaa down.\n",
      "5 little pigs come out, or I'll huff, and I'll puff, and I'll blow your aaaaaa down.\n",
      "6 little pigs come out, or I'll huff, and I'll puff, and I'll blow your aaaaaaa down.\n",
      "7 little pigs come out, or I'll huff, and I'll puff, and I'll blow your aaaaaaaa down.\n",
      "8 little pigs come out, or I'll huff, and I'll puff, and I'll blow your aaaaaaaaa down.\n",
      "9 little pigs come out, or I'll huff, and I'll puff, and I'll blow your aaaaaaaaaa down.\n"
     ]
    }
   ],
   "source": [
    "# % operator\n",
    "xx = 'a'\n",
    "for i in range(0,10):\n",
    "    text10 = \"%d little pigs come out, or I'll %s, and I'll %s, and I'll blow your %s down.\" % (i, 'huff', 'puff', xx)\n",
    "    xx += 'a'\n",
    "    print(text10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Writh in txt file\n",
    "\n",
    "text_file = open(r\"D:\\Text9\\data\\123.txt\", \"w\",encoding='utf-8')\n",
    "for i in range(0,10):\n",
    "    text10 = \"%d little pigs come out, or I'll %s, and I'll %s, and I'll blow your %s down.\\n\" % (i, 'huff', 'puff', 'house')\n",
    "\n",
    "    #print(text10)\n",
    "    text_file.write(text10)\n",
    "text_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
