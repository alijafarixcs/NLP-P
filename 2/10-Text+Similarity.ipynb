{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 33)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Stopword = ['همچنان', 'مدت', 'چیز', 'سایر', 'جا', 'طی', 'کل', 'کنونی', 'بیرون','های', 'مثلا', 'کامل','ها', 'کاملا','گیرد','شود','است', 'آنکه', \n",
    "            'موارد', 'واقعی', 'امور', 'اکنون', 'بطور', 'بخشی', 'تحت', 'چگونه', 'عدم', 'نوعی', 'حاضر', 'وضع', 'مقابل', 'کنار', 'خویش', 'نگاه', 'درون',\n",
    "            'زمانی', 'بنابراین', 'تو', 'خیلی', 'بزرگ', 'خودش', 'جز', 'اینجا', 'مختلف', 'توسط', 'نوع', 'همچنین', 'آنجا', 'قبل', 'جناح', 'اینها', 'طور', 'شاید',\n",
    "            'ایشان', 'جهت', 'طریق', 'مانند', 'پیدا', 'ممکن', 'کسانی', 'جای', 'کسی', 'غیر', 'بی', 'قابل', 'درباره', 'جدید', 'وقتی', 'اخیر', 'چرا', 'بیش',\n",
    "            'روی', 'طرف', 'جریان', 'زیر', 'آنچه', 'البته', 'فقط', 'چیزی', 'چون', 'برابر', 'هنوز', 'بخش', 'زمینه', 'بین', 'بدون', 'استفاد', 'همان', 'نشان',\n",
    "            'بسیاری', 'بعد', 'عمل', 'روز', 'اعلام', 'چند', 'آنان', 'بلکه', 'امروز', 'تمام', 'بیشتر', 'آیا', 'برخی', 'علیه', 'دیگری', 'ویژه', 'گذشته', 'انجام',\n",
    "            'حتی', 'داده', 'راه', 'سوی', 'ولی', 'زمان', 'حال', 'تنها', 'بسیار', 'یعنی', 'عنوان', 'همین', 'هبچ', 'پیش', 'وی', 'یکی', 'اینکه', 'وجود'\n",
    "            , 'شما', 'پس', 'چنین', 'میان', 'مورد', 'چه', 'اگر', 'همه', 'نه', 'دیگر', 'آنها', 'باید', 'هر', 'او', 'ما', 'من', 'تا', 'نیز', 'اما', \n",
    "            'یک', 'خود', 'بر', 'یا', 'هم','ای', 'را','دارد', 'این',\"می\", 'با','دارد','،',',','.', 'آن', 'برای', 'و', 'در', 'به', 'که', 'از']\n",
    "\n",
    "\n",
    "Texts = [\"دسته بندی متون بوسیله تکنیک های داده کاوی و یادگیری ماشین \",\n",
    "         \"ارزیابی و ترکیب الگوریتم های یادگیری ماشین و تکنیک های دسته بندی متن کاوی جهت بهبود طبقه بندی متون فارسی\",\n",
    "         \"دسته بندی و پیش بینی وضعیت تحصیلی دانشجویان با استفاده از تکنیک های داده کاوی\",\n",
    "         \"دسته بندی مشتریان بیمه با استفاده از داده کاوی\",\n",
    "         \"تشخیص بیماری قلبی با تکنیک های طبقه بندی داده کاوی\",\n",
    "         \"دسته بندی مشتریان فروشگاه اینترنتی به منظور ارایه خدمات ویژه با به کارگیری سیستم فازی\"]\n",
    "\n",
    "\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words=Stopword)\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(Texts)\n",
    "tfidf_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<6x33 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 55 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(tfidf_matrix[0:1],tfidf_matrix)\n",
    "\n",
    "tfidf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.50520859, 0.22149502, 0.20382914, 0.18946262,\n",
       "        0.07517972]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(tfidf_matrix[0:1],tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 [1.0000000000000002, 0.505208588508129, 0.22149501675498606, 0.20382913914064726, 0.18946262092761987, 0.07517972058137548] \n",
      "\n",
      "2 [0.505208588508129, 1.0000000000000002, 0.1647706664438106, 0.16308813239527364, 0.24669271095151218, 0.06751959727007581] \n",
      "\n",
      "3 [0.22149501675498606, 0.1647706664438106, 1.0, 0.33216377848523154, 0.15986493411542602, 0.06343520964037108] \n",
      "\n",
      "4 [0.20382913914064726, 0.16308813239527364, 0.33216377848523154, 1.0000000000000002, 0.12391814052000091, 0.21389405052238084] \n",
      "\n",
      "5 [0.18946262092761987, 0.24669271095151218, 0.15986493411542602, 0.12391814052000091, 1.0000000000000002, 0.030793500445224022] \n",
      "\n",
      "6 [0.07517972058137548, 0.06751959727007581, 0.06343520964037108, 0.21389405052238084, 0.030793500445224022, 0.9999999999999999] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,len(Texts)):\n",
    "    print(i+1,list(cosine_similarity(tfidf_matrix[i:i+1],tfidf_matrix)[0]),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
